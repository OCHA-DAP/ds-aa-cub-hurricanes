

## Three-stage trigger optimization

Iterate over options to get trigger options that meet 3.7-yr RP. Variables iterated over:

- wind speed threshold (while storm is in, or is forecast to be in, the ZMA)
- rainfall aggregation (`mean`, or quantiles 50, 80, 90, 95)
- rainfall threshold (two-day sum per pixel during the period that the storm is in, or is forecast to be in, the ZMA, Â±1 day)


```{python}
%load_ext jupyter_black
%load_ext autoreload
%autoreload 2
```


```{python}
import ocha_stratus as stratus
import pandas as pd
import matplotlib.pyplot as plt
import matplotlib.patches as mpatches

# import optuna
from tqdm.auto import tqdm

from src.datasources import ibtracs
from src.datasources.ibtracs import knots2cat
from src.constants import *
```

## Load and combine data

### Load Storm Data

We load historical storm data from the IBTrACS database, filtering for North Atlantic (NA) storms from 2000 onwards. We extract key identifiers including storm ID, ATCF ID, and name, and standardize the ATCF IDs to lowercase.

```{python}
df_storms = ibtracs.load_storms()
cols = ["sid", "atcf_id", "name"]
df_storms = df_storms[
    (df_storms["sid"].str[:4].astype(int) >= 2000)
    & (df_storms["genesis_basin"] == "NA")
][cols]
df_storms["atcf_id"] = df_storms["atcf_id"].str.lower()
```

### Load Impact Data

We load impact data from EM-DAT and CERF databases, which contain information about humanitarian impacts including affected populations, deaths, damage costs, and CERF funding. We create a CERF flag to identify storms that received CERF funding and apply a manual correction for Hurricane Ike's affected population.

```{python}
blob_name = f"{PROJECT_PREFIX}/processed/impact/emdat_cerf_upto2024.parquet"
df_impact = stratus.load_parquet_from_blob(blob_name)
df_impact["cerf"] = ~df_impact["Amount in US$"].isnull()
cols = [
    "sid",
    "cerf",
    "Total Affected",
    "Total Deaths",
    "Total Damage, Adjusted ('000 US$)",
    "Amount in US$",
]
df_impact = df_impact[cols]
df_impact.loc[df_impact["sid"] == IKE, "Total Affected"] = 2.6e6
```

### Load Observed Storm Statistics with Quantiles

We load observed storm statistics that include rainfall quantiles (50th, 80th, 90th, 95th percentiles) for the Zone of Maximum Activity (ZMA). This dataset contains detailed rainfall patterns for each storm.

```{python}
blob_name = (
    f"{PROJECT_PREFIX}/processed/storm_stats/zma_stats_imerg_quantiles.parquet"
)

df_stats_obsv = stratus.load_parquet_from_blob(blob_name)
```

### Load Observed Storm Statistics (Mean Only)

We also load a simplified version of the storm statistics that contains only mean rainfall values. This will be merged with the quantile data to provide a complete picture of rainfall patterns.

```{python}
blob_name = f"{PROJECT_PREFIX}/processed/storm_stats/zma_stats.parquet"

df_stats_obsv_meanonly = stratus.load_parquet_from_blob(blob_name)
```

### Clean Observed Statistics

We clean the observed statistics by removing unnecessary columns that contain totals, above-threshold values, 3-day rolling averages, and landfall-specific data, as these are not needed for our optimization analysis.

```{python}
drop_cols = [
    x
    for x in df_stats_obsv
    if any([s in x for s in ["_total", "_abv", "_roll3", "_landfall"]])
]
df_stats_obsv = df_stats_obsv.drop(columns=drop_cols)
```

### Merge Observed Statistics

We merge the quantile-based observed statistics with the mean-only dataset to get comprehensive rainfall data. We also remove validation columns that are not needed for the optimization process.

```{python}
df_stats_obsv = df_stats_obsv.merge(
    df_stats_obsv_meanonly[["sid", "max_roll2_mean"]]
).drop(columns=[x for x in df_stats_obsv if "valid" in x])
```

### Load Forecast Data

We load forecast data from the National Hurricane Center (NHC) monitors that have been combined with CHIRPS-GEFS rainfall forecasts. This data provides forecast-based storm characteristics that can be used for early warning triggers.

```{python}
blob_name =  (
    f"{PROJECT_PREFIX}/processed/nhc/monitors_nhc_chirpsgefs.parquet"
)
df_monitors_fcast = stratus.load_parquet_from_blob(blob_name)
```

### Process Forecast Statistics

We process the forecast monitoring data by filtering for "action" level forecasts (the most severe category), then group by storm ID to get the maximum forecast values for each storm. We remove unnecessary time and category columns.

```{python}
df_stats_fcast = (
    df_monitors_fcast[df_monitors_fcast["lt_name"] == "action"]
    .groupby("atcf_id")
    .max()
    .reset_index()
    .dropna()
    .drop(columns=["issue_time", "lt_name"])
)

```

### Combine All Datasets

We create a comprehensive dataset by merging impact data, storm metadata, forecast statistics, and observed statistics. We rename observed statistics columns to distinguish them from forecast data (adding "_obsv" suffix) and extract the year from storm IDs. Finally, we clean up data types by filling missing values and converting appropriate columns to integers.

```{python}
df_stats = (
    df_impact.merge(df_storms, how="left")
    .merge(df_stats_fcast, how="left")
    .merge(
        df_stats_obsv.rename(
            columns={x: x.replace("roll2", "obsv") for x in df_stats_obsv}
            | {"max_roll2_mean": "mean_obsv", "wind_speed_max": "wind_obsv"}
        ),
        how="left",
    )
)
df_stats["year"] = df_stats["sid"].str[:4]

int_cols = [
    "year",
    # "wind",
    # "wind_obsv",
    "Total Affected",
    "Total Deaths",
    "Total Damage, Adjusted ('000 US$)",
    "Amount in US$",
]
df_stats[int_cols] = df_stats[int_cols].fillna(0)
df_stats[int_cols] = df_stats[int_cols].astype(int)
```

```{python}
# | eval: false
# | echo: false

# Diagnostic script to identify NA sources in the data merging process

print("=== DIAGNOSTIC ANALYSIS FOR NA VALUES ===\n")

# 1. Check the shapes and key columns of each dataset
print("1. Dataset shapes and key info:")
print(f"df_impact shape: {df_impact.shape}")
print(f"df_storms shape: {df_storms.shape}")
print(f"df_stats_fcast shape: {df_stats_fcast.shape}")
print(f"df_stats_obsv shape: {df_stats_obsv.shape}")
print()

# 2. Check the merge keys
print("2. Merge key analysis:")
print(f"Unique storms in df_impact: {df_impact['sid'].nunique()}")
print(f"Unique storms in df_storms: {df_storms['sid'].nunique()}")
print(
    f"Unique storms in df_stats_fcast: {df_stats_fcast['atcf_id'].nunique()}"
)
print(f"Unique storms in df_stats_obsv: {df_stats_obsv['sid'].nunique()}")
print()

# 3. Check for key mismatches
print("3. Key overlap analysis:")
# After first merge (impact + storms)
df_temp1 = df_impact.merge(df_storms, how="left")
print(f"After impact+storms merge: {df_temp1.shape}")

# Check which storms have forecast data
storms_with_forecast = set(df_stats_fcast["atcf_id"].dropna())
storms_in_temp1 = set(df_temp1["atcf_id"].dropna())
print(f"Storms in temp1 with atcf_id: {len(storms_in_temp1)}")
print(f"Storms with forecast data: {len(storms_with_forecast)}")
print(f"Overlap: {len(storms_in_temp1.intersection(storms_with_forecast))}")
print(
    f"Missing forecast data for: {len(storms_in_temp1 - storms_with_forecast)} storms"
)
print()

# 4. Check after forecast merge
df_temp2 = df_temp1.merge(df_stats_fcast, how="left")
print(f"After +forecast merge: {df_temp2.shape}")

# Check which columns have NAs after forecast merge
forecast_cols = df_stats_fcast.columns.tolist()
forecast_nas = df_temp2[forecast_cols].isnull().sum()
print("NAs in forecast columns after merge:")
for col, na_count in forecast_nas.items():
    if na_count > 0:
        print(f"  {col}: {na_count} NAs")
print()

# 5. Check observed data merge
storms_with_obsv = set(df_stats_obsv["sid"].dropna())
print(f"Storms with observed data: {len(storms_with_obsv)}")
print(
    f"Overlap with temp data: {len(set(df_temp2['sid']).intersection(storms_with_obsv))}"
)
print(
    f"Missing observed data for: {len(set(df_temp2['sid']) - storms_with_obsv)} storms"
)
print()

# 6. Final merge analysis
df_final = df_temp2.merge(
    df_stats_obsv.rename(
        columns={x: x.replace("roll2", "obsv") for x in df_stats_obsv}
        | {"max_roll2_mean": "mean_obsv", "wind_speed_max": "wind_obsv"}
    ),
    how="left",
)
print(f"Final dataset shape: {df_final.shape}")

# 7. Check which storms have complete data
print("7. Data completeness analysis:")
print(f"Storms with forecast wind data: {df_final['wind'].notna().sum()}")
print(f"Storms with observed wind data: {df_final['wind_obsv'].notna().sum()}")
print(
    f"Storms with both wind data: {(df_final['wind'].notna() & df_final['wind_obsv'].notna()).sum()}"
)
print(f"Storms missing forecast wind: {df_final['wind'].isna().sum()}")
print(f"Storms missing observed wind: {df_final['wind_obsv'].isna().sum()}")
print()

# 8. Show examples of problematic storms
print("8. Examples of storms with missing data:")
missing_forecast = df_final[df_final["wind"].isna()]
if len(missing_forecast) > 0:
    print("Storms missing forecast data:")
    print(missing_forecast[["sid", "name", "atcf_id"]].head())
    print()

missing_obsv = df_final[df_final["wind_obsv"].isna()]
if len(missing_obsv) > 0:
    print("Storms missing observed data:")
    print(missing_obsv[["sid", "name", "atcf_id"]].head())
    print()

# 9. Check data types and potential format issues
print("9. Data type analysis:")
print("ATCF ID formats in storms data:")
print(df_storms["atcf_id"].head(10).tolist())
print("ATCF ID formats in forecast data:")
print(df_stats_fcast["atcf_id"].head(10).tolist())
print()

# 10. Summary recommendation
print("10. RECOMMENDATIONS:")
if df_final["wind"].isna().sum() > 0:
    print(
        "- Missing forecast data: Consider if these storms occurred outside forecast period"
    )
if df_final["wind_obsv"].isna().sum() > 0:
    print(
        "- Missing observed data: Check if observation data coverage matches storm periods"
    )
if len(storms_in_temp1 - storms_with_forecast) > 0:
    print(
        "- ATCF ID mismatch: Check if ATCF IDs are consistently formatted between datasets"
    )
```

### Save Combined Dataset

We save the combined forecast and observed statistics dataset to cloud storage for future use and analysis.

```{python}
# | eval: false

blob_name = f"{PROJECT_PREFIX}/processed/fcast_obsv_combined_stats.parquet"
stratus.upload_parquet_to_blob(df_stats, blob_name)
```

## Optimization

### Set Target Return Period

We set our target to find trigger combinations that activate exactly 7 times over the historical period, corresponding to a 3.7-year return period (assuming roughly 26 years of data from 2000-2025).

```{python}
target_years = 7
```

### Define Impact Metrics

We define the impact columns that will be used to evaluate the effectiveness of different trigger combinations. These include affected populations, deaths, economic damage, CERF funding amounts, and a binary CERF flag.

```{python}
impact_cols = [
    "Total Affected",
    "Total Deaths",
    "Total Damage, Adjusted ('000 US$)",
    "Amount in US$",
    "cerf"
]
```

### Define Forecast Rainfall Aggregation Methods

We specify the rainfall aggregation methods to test for forecast data. This includes the mean and specific quantiles (50th, 80th, and 95th percentiles) that represent different levels of rainfall intensity.

```{python}
fcast_rain_cols = ["mean"] + [f"q{x}" for x in [50, 80, 95]]
```

### Define Observed Rainfall Aggregation Methods

We create corresponding observed rainfall column names by adding the "_obsv" suffix to match the forecast column names.

```{python}
obsv_rain_cols = [x + "_obsv" for x in fcast_rain_cols]
```

### Display Forecast Rainfall Columns

We display the forecast rainfall aggregation methods that will be tested in the optimization.

```{python}
fcast_rain_cols
```

### Comprehensive Trigger Optimization

This is the main optimization loop that systematically tests all possible combinations of trigger parameters. We iterate through:

1. **Wind speed thresholds** for both forecast and observed data
2. **Rainfall aggregation methods** (mean, 50th, 80th, 95th percentiles)  
3. **Rainfall thresholds** for each aggregation method

For each combination, we:
- Check if the forecast-based trigger would activate
- Check if the observed-based trigger would activate  
- Count storms that would trigger either forecast OR observed conditions
- Only keep combinations that trigger exactly 7 times (target return period)
- Calculate total impact metrics for those triggered storms

The optimization includes an early stopping mechanism: if wind thresholds alone don't yield enough years, we skip further rainfall filtering since it would only reduce the count further.

```{python}
#| eval: false

# once confirmed that this loop runs in aboout 15 minutes or so on my computer, I just set `eval: false` for future runs and book rendering. We will load the result later from the written parquet.
rows = []
tqdm_level = 1
count = 0
for fcast_wind_thresh in tqdm(
    df_stats["wind"].unique(), disable=tqdm_level < 1
):
    for obsv_wind_thresh in tqdm(
        df_stats["wind_obsv"].unique(), disable=tqdm_level < 2
    ):
        dff_wind = df_stats[
            (df_stats["wind"] >= fcast_wind_thresh)
            | (df_stats["wind_obsv"] >= obsv_wind_thresh)
        ]
        # if filtering already limits to too few years, skip
        # since we know that further filtering will only result in lower number
        if dff_wind["year"].nunique() < target_years:
            continue
        for fcast_rain_col in fcast_rain_cols:
            for fcast_rain_thresh in df_stats[fcast_rain_col].unique():
                for obsv_rain_col in obsv_rain_cols:
                    for obsv_rain_thresh in df_stats[obsv_rain_col].unique():
                        count += 1
                        # check years triggered with forecast
                        triggered_fcast = (
                            df_stats["wind"] >= fcast_wind_thresh
                        ) & (df_stats[fcast_rain_col] >= fcast_rain_thresh)
                        # check years triggered with forecast
                        triggered_obsv = (
                            df_stats["wind_obsv"] >= obsv_wind_thresh
                        ) & (df_stats[obsv_rain_col] >= obsv_rain_thresh)

                        # check years triggered with either
                        dff_triggered = df_stats[
                            triggered_fcast | triggered_obsv
                        ]
                        if dff_triggered["year"].nunique() == target_years:
                            row_out = dff_triggered[impact_cols].sum()
                            row_out["fcast_wind"] = fcast_wind_thresh
                            row_out["fcast_rain_col"] = fcast_rain_col
                            row_out["fcast_rain_thresh"] = fcast_rain_thresh
                            row_out["obsv_wind"] = obsv_wind_thresh
                            row_out["obsv_rain_col"] = obsv_rain_col
                            row_out["obsv_rain_thresh"] = obsv_rain_thresh
                            row_out["n_years_fcast"] = df_stats[
                                triggered_fcast
                            ]["year"].nunique()
                            row_out["n_years_obsv"] = df_stats[triggered_obsv][
                                "year"
                            ].nunique()
                            rows.append(row_out)
```

### Display Total Iterations

We display the total number of parameter combinations tested during the optimization process.

```{python}
#| eval: false
count
```

### Compile Optimization Results

 - We convert the collected results from the optimization loop into a pandas DataFrame for analysis. Each row represents a valid trigger combination that activates exactly 7 times

- We sort and display the optimization results by total affected population (descending) to identify the trigger combinations that would have captured the storms with the highest humanitarian impact.

- We save the complete optimization results to cloud storage for further analysis and decision-making about trigger thresholds.

```{python}
# | eval: false

df_metrics = pd.concat(rows, axis=1).T
df_metrics.sort_values("Total Affected", ascending=False)
```

```{python}
# | eval: false

blob_name = (
    f"{PROJECT_PREFIX}/processed/fcast_obsv_combined_trigger_metrics.parquet"
)
stratus.upload_parquet_to_blob(df_metrics, blob_name)
```



```{python}
# | eval: false
# not really necessary until we decide if we want to keep optima code below.

df_metrics = stratus.load_parquet_from_blob(blob_name)
```

## Using `optima` (Experimental)

Can ignore for now, didn't use, was just a way to try and speed things up. But I don't think the problem is well suited to this approach

### Experimental Optuna Implementation

This section contains an experimental implementation using the Optuna optimization library. The approach attempts to use Bayesian optimization to find optimal trigger combinations more efficiently than brute force, but it wasn't used in the final analysis as the discrete nature of the problem makes it less suitable for this optimization approach.

```{python}
#| eval: false

# --- Storage for all results ---
results_rows = []

# --- Loop over each impact column ---
for impact_col in impact_cols:
    print(f"\nð Optimizing for impact column: {impact_col}")

    def objective(trial):
        # Sample threshold values
        fcast_wind_thresh = trial.suggest_int(
            "fcast_wind_thresh",
            int(df_stats["wind"].min()),
            int(df_stats["wind"].max()),
            step=5,
        )
        obsv_wind_thresh = trial.suggest_int(
            "obsv_wind_thresh",
            int(df_stats["wind_obsv"].min()),
            int(df_stats["wind_obsv"].max()),
            step=5,
        )
        fcast_rain_col = trial.suggest_categorical(
            "fcast_rain_col", fcast_rain_cols
        )
        obsv_rain_col = trial.suggest_categorical(
            "obsv_rain_col", obsv_rain_cols
        )
        fcast_rain_thresh = trial.suggest_int(
            "fcast_rain_thresh",
            int(df_stats[fcast_rain_col].min()),
            int(df_stats[fcast_rain_col].max()),
        )
        obsv_rain_thresh = trial.suggest_int(
            "obsv_rain_thresh",
            int(df_stats[obsv_rain_col].min()),
            int(df_stats[obsv_rain_col].max()),
        )

        # Filtering logic (trigger condition)
        dff_triggered = df_stats[
            (
                (df_stats["wind"] >= fcast_wind_thresh)
                & (df_stats[fcast_rain_col] >= fcast_rain_thresh)
            )
            | (
                (df_stats["wind_obsv"] >= obsv_wind_thresh)
                & (df_stats[obsv_rain_col] >= obsv_rain_thresh)
            )
        ]

        # Skip if not enough years are represented
        if dff_triggered["year"].nunique() != target_years:
            raise optuna.exceptions.TrialPruned()

        # Maximize the sum of the selected impact column
        score = dff_triggered[impact_col].sum()
        return -score  # Optuna minimizes, so negate

    # Create and run study
    study = optuna.create_study(direction="minimize")
    study.optimize(objective, n_trials=200, show_progress_bar=True)
    optuna.visualization.plot_optimization_history(study).show()
    # Store result as a row dict
    row = {
        "impact_col": impact_col,
        "best_score": -study.best_value,
        **study.best_params,
    }
    results_rows.append(row)

# --- Final results DataFrame ---
results_df = pd.DataFrame(results_rows)
print("\nð Optimization results:")
print(results_df)
```

### Plot Optimization History

This code visualizes the optimization progress over iterations, showing how the objective function value changes as Optuna explores different parameter combinations.

```{python}
#| eval: false

optuna.visualization.plot_optimization_history(study).show()
```

### Display Results for Each Impact Column

This code loops through the optimization results for each impact column and displays the storms that would have been triggered by the optimal parameter combination. It creates a trigger flag and sorts storms by their impact levels to show which storms would have been captured.

```{python}
#| eval: false
for impact_col, row in results_df.set_index("impact_col").iterrows():
    df_disp = df_stats.copy()
    fcast_wind_thresh = row["fcast_wind_thresh"]
    obsv_wind_thresh = row["obsv_wind_thresh"]
    fcast_rain_col = row["fcast_rain_col"]
    fcast_rain_thresh = row["fcast_rain_thresh"]
    obsv_rain_col = row["obsv_rain_col"]
    obsv_rain_thresh = row["obsv_rain_thresh"]
    df_disp["trig"] = (
        (df_stats["wind"] >= fcast_wind_thresh)
        & (df_stats[fcast_rain_col] >= fcast_rain_thresh)
    ) | (
        (df_stats["wind_obsv"] >= obsv_wind_thresh)
        & (df_stats[obsv_rain_col] >= obsv_rain_thresh)
    )
    print(impact_col)
    print(row)
    display(df_disp.sort_values(impact_col, ascending=False))
```


